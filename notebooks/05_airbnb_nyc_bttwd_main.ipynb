{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Airbnb NYC 数据集 BT-TWD 可行性实验\n",
        "\n",
        "本 notebook 按步骤运行：加载配置 → 读取数据 → 预处理 → 桶树划分 → 基线与 BTTWD k 折实验 → 桶级分析。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "84f86423",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【INFO】【2025-12-11 17:31:52】【配置加载】已读取 e:\\yan\\组\\三支决策\\机器学习\\BT_TWD\\configs\\airbnb_nyc.yaml\n",
            "【INFO】【2025-12-11 17:31:55】【步骤0摘要】环境准备完毕，路径与随机种子已设置。\n"
          ]
        }
      ],
      "source": [
        "# 步骤0：环境与路径设置\n",
        "import os, sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# 将项目根目录加入路径，便于导入 bttwdlib\n",
        "root_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
        "if root_path not in sys.path:\n",
        "    sys.path.append(root_path)\n",
        "\n",
        "from bttwdlib import (\n",
        "    load_yaml_cfg,\n",
        "    show_cfg,\n",
        "    load_dataset,\n",
        "    prepare_features_and_labels,\n",
        "    BucketTree,\n",
        "    run_kfold_experiments,\n",
        "    log_info,\n",
        "    set_global_seed,\n",
        ")\n",
        "\n",
        "cfg_path = Path(root_path) / \"configs\" / \"airbnb_nyc.yaml\"\n",
        "cfg = load_yaml_cfg(cfg_path)\n",
        "set_global_seed(cfg.get('SEED', {}).get('global_seed', 42))\n",
        "log_info('【步骤0摘要】环境准备完毕，路径与随机种子已设置。')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1c0a166d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【INFO】【2025-12-11 17:31:55】【配置-数据】数据集=airbnb_nyc, k折=5, 目标列=price, 正类=\"1\"\n",
            "【INFO】【2025-12-11 17:31:55】【配置-BTTWD】阈值模式=None, 全局模型=xgb, 桶内模型=none, 后验估计器(兼容字段)=logreg\n",
            "【INFO】【2025-12-11 17:31:55】【配置-基线】LogReg启用=False, RandomForest启用=True, KNN启用=True, XGBoost启用=True\n",
            "【INFO】【2025-12-11 17:31:55】【步骤1摘要】配置文件加载完成，关键参数检查通过。\n"
          ]
        }
      ],
      "source": [
        "# 步骤1：加载配置\n",
        "show_cfg(cfg)\n",
        "log_info('【步骤1摘要】配置文件加载完成，关键参数检查通过。')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3018ab35",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【INFO】【2025-12-11 17:31:55】【数据加载】文本表格 ..\\data\\AB_NYC\\AB_NYC_2019.csv 已读取，样本数=48895，列数=16\n",
            "【INFO】【2025-12-11 17:31:55】【目标变换】已按阈值 255 生成二分类标签列 high_price，正类取 > 255\n",
            "【INFO】【2025-12-11 17:31:55】【数据集信息】名称=airbnb_nyc，样本数=48895，目标列=high_price，正类比例=10.52%\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>host_id</th>\n",
              "      <th>host_name</th>\n",
              "      <th>neighbourhood_group</th>\n",
              "      <th>neighbourhood</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>room_type</th>\n",
              "      <th>price</th>\n",
              "      <th>minimum_nights</th>\n",
              "      <th>number_of_reviews</th>\n",
              "      <th>last_review</th>\n",
              "      <th>reviews_per_month</th>\n",
              "      <th>calculated_host_listings_count</th>\n",
              "      <th>availability_365</th>\n",
              "      <th>high_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2539</td>\n",
              "      <td>Clean &amp; quiet apt home by the park</td>\n",
              "      <td>2787</td>\n",
              "      <td>John</td>\n",
              "      <td>Brooklyn</td>\n",
              "      <td>Kensington</td>\n",
              "      <td>40.64749</td>\n",
              "      <td>-73.97237</td>\n",
              "      <td>Private room</td>\n",
              "      <td>149</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>2018-10-19</td>\n",
              "      <td>0.21</td>\n",
              "      <td>6</td>\n",
              "      <td>365</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2595</td>\n",
              "      <td>Skylit Midtown Castle</td>\n",
              "      <td>2845</td>\n",
              "      <td>Jennifer</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>Midtown</td>\n",
              "      <td>40.75362</td>\n",
              "      <td>-73.98377</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>225</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>2019-05-21</td>\n",
              "      <td>0.38</td>\n",
              "      <td>2</td>\n",
              "      <td>355</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3647</td>\n",
              "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
              "      <td>4632</td>\n",
              "      <td>Elisabeth</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>Harlem</td>\n",
              "      <td>40.80902</td>\n",
              "      <td>-73.94190</td>\n",
              "      <td>Private room</td>\n",
              "      <td>150</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>365</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3831</td>\n",
              "      <td>Cozy Entire Floor of Brownstone</td>\n",
              "      <td>4869</td>\n",
              "      <td>LisaRoxanne</td>\n",
              "      <td>Brooklyn</td>\n",
              "      <td>Clinton Hill</td>\n",
              "      <td>40.68514</td>\n",
              "      <td>-73.95976</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>89</td>\n",
              "      <td>1</td>\n",
              "      <td>270</td>\n",
              "      <td>2019-07-05</td>\n",
              "      <td>4.64</td>\n",
              "      <td>1</td>\n",
              "      <td>194</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5022</td>\n",
              "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
              "      <td>7192</td>\n",
              "      <td>Laura</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>East Harlem</td>\n",
              "      <td>40.79851</td>\n",
              "      <td>-73.94399</td>\n",
              "      <td>Entire home/apt</td>\n",
              "      <td>80</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>2018-11-19</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id                                              name  host_id  \\\n",
              "0  2539                Clean & quiet apt home by the park     2787   \n",
              "1  2595                             Skylit Midtown Castle     2845   \n",
              "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n",
              "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
              "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
              "\n",
              "     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
              "0         John            Brooklyn    Kensington  40.64749  -73.97237   \n",
              "1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n",
              "2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n",
              "3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n",
              "4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n",
              "\n",
              "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
              "0     Private room    149               1                  9  2018-10-19   \n",
              "1  Entire home/apt    225               1                 45  2019-05-21   \n",
              "2     Private room    150               3                  0         NaN   \n",
              "3  Entire home/apt     89               1                270  2019-07-05   \n",
              "4  Entire home/apt     80              10                  9  2018-11-19   \n",
              "\n",
              "   reviews_per_month  calculated_host_listings_count  availability_365  \\\n",
              "0               0.21                               6               365   \n",
              "1               0.38                               2               355   \n",
              "2                NaN                               1               365   \n",
              "3               4.64                               1               194   \n",
              "4               0.10                               1                 0   \n",
              "\n",
              "   high_price  \n",
              "0           0  \n",
              "1           0  \n",
              "2           0  \n",
              "3           0  \n",
              "4           0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "用于建模的标签列: high_price\n",
            "原始目标列: price\n",
            "count    48895.000000\n",
            "mean       152.720687\n",
            "std        240.154170\n",
            "min          0.000000\n",
            "25%         69.000000\n",
            "50%        106.000000\n",
            "75%        175.000000\n",
            "max      10000.000000\n",
            "Name: price, dtype: float64\n",
            "【INFO】【2025-12-11 17:31:55】【步骤2摘要】Airbnb NYC 原始数据加载与基本统计完成。\n"
          ]
        }
      ],
      "source": [
        "# 步骤2：加载原始数据\n",
        "df_raw, target_col_model = load_dataset(cfg)  # 这里返回的是用于建模的标签列，例如 \"label\"\n",
        "\n",
        "display(df_raw.head())\n",
        "print(\"用于建模的标签列:\", target_col_model)\n",
        "\n",
        "# 1）画 0/1 标签（高价/非高价）的比例\n",
        "class_counts = df_raw[target_col_model].value_counts(normalize=True)\n",
        "ax = class_counts.plot(kind='bar', title='高价 vs 非高价比例')\n",
        "plt.ylabel('比例')\n",
        "\n",
        "fig_path = os.path.join(root_path, cfg['OUTPUT']['figs_dir'], 'class_distribution.png')\n",
        "os.makedirs(os.path.dirname(fig_path), exist_ok=True)\n",
        "plt.savefig(fig_path, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# 2）如果想看原始标签列的分布，可以另外单独分析：\n",
        "raw_target_col = cfg['DATA']['target_col']  # 这里是原始标签列\n",
        "print(\"原始目标列:\", raw_target_col)\n",
        "print(df_raw[raw_target_col].describe())\n",
        "\n",
        "log_info('【步骤2摘要】Airbnb NYC 原始数据加载与基本统计完成。')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "941dcc9e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【INFO】【2025-12-11 17:31:55】【预处理】连续特征=7个，类别特征=3个\n",
            "【INFO】【2025-12-11 17:31:55】【预处理】编码后维度=233\n",
            "【INFO】【2025-12-11 17:31:55】【预处理】编码特征维度=233，样本数=48895\n",
            "【INFO】【2025-12-11 17:31:55】【步骤3摘要】特征预处理完成：连续=7，类别=3，编码维度=233。\n"
          ]
        }
      ],
      "source": [
        "# 步骤3：预处理与特征工程\n",
        "X, y, meta = prepare_features_and_labels(df_raw, cfg)\n",
        "log_info(f'【预处理】编码特征维度={X.shape[1]}，样本数={X.shape[0]}')\n",
        "log_info(f\"【步骤3摘要】特征预处理完成：连续={len(meta['continuous_cols'])}，类别={len(meta['categorical_cols'])}，编码维度={X.shape[1]}。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6cf6e264",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【INFO】【2025-12-11 17:31:55】【桶树】已为样本生成桶ID，共 45 个组合\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bucket_id</th>\n",
              "      <th>count</th>\n",
              "      <th>pos_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>L1_neighbourhood_group=manhattan|L2_room_type=...</td>\n",
              "      <td>6276</td>\n",
              "      <td>0.100671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>L1_neighbourhood_group=brooklyn|L2_room_type=p...</td>\n",
              "      <td>5190</td>\n",
              "      <td>0.058824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>L1_neighbourhood_group=brooklyn|L2_room_type=e...</td>\n",
              "      <td>4857</td>\n",
              "      <td>0.031915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>L1_neighbourhood_group=manhattan|L2_room_type=...</td>\n",
              "      <td>4311</td>\n",
              "      <td>0.011111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>L1_neighbourhood_group=manhattan|L2_room_type=...</td>\n",
              "      <td>4020</td>\n",
              "      <td>0.004149</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           bucket_id  count  pos_rate\n",
              "0  L1_neighbourhood_group=manhattan|L2_room_type=...   6276  0.100671\n",
              "1  L1_neighbourhood_group=brooklyn|L2_room_type=p...   5190  0.058824\n",
              "2  L1_neighbourhood_group=brooklyn|L2_room_type=e...   4857  0.031915\n",
              "3  L1_neighbourhood_group=manhattan|L2_room_type=...   4311  0.011111\n",
              "4  L1_neighbourhood_group=manhattan|L2_room_type=...   4020  0.004149"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【INFO】【2025-12-11 17:31:56】【步骤4摘要】桶树划分完成，共有 45 个叶子桶。\n"
          ]
        }
      ],
      "source": [
        "# 步骤4：构建桶树并检查划分\n",
        "feature_cols_for_bucket = [c for c in df_raw.columns if c != target_col_model]\n",
        "\n",
        "bucket_tree = BucketTree(\n",
        "    cfg['BTTWD']['bucket_levels'],\n",
        "    feature_names=feature_cols_for_bucket\n",
        ")\n",
        "\n",
        "bucket_ids_full = bucket_tree.assign_buckets(df_raw[feature_cols_for_bucket])\n",
        "\n",
        "bucket_df = bucket_ids_full.value_counts().reset_index()\n",
        "bucket_df.columns = ['bucket_id', 'count']\n",
        "\n",
        "bucket_df['pos_rate'] = (\n",
        "    df_raw.groupby(bucket_ids_full)[target_col_model]\n",
        "    .apply(lambda s: (s == 1).mean())\n",
        "    .values\n",
        ")\n",
        "display(bucket_df.head())\n",
        "bucket_df.set_index('bucket_id')['count'].plot(kind='bar', figsize=(12,4), title='桶样本数分布')\n",
        "fig_bucket = os.path.join(root_path, cfg['OUTPUT']['figs_dir'], 'bucket_metrics_bar.png')\n",
        "plt.savefig(fig_bucket, bbox_inches='tight')\n",
        "plt.close()\n",
        "log_info(f'【步骤4摘要】桶树划分完成，共有 {bucket_ids_full.nunique()} 个叶子桶。')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f58dfd86",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【INFO】【2025-12-11 17:31:56】【步骤5】基线模型将在整体交叉验证中一并运行。\n",
            "【INFO】【2025-12-11 17:31:56】【步骤5摘要】基线模型性能将作为后续对比基准。\n"
          ]
        }
      ],
      "source": [
        "# 步骤5：运行基线模型 k 折实验\n",
        "# 基线部分在 run_kfold_experiments 内统一调度\n",
        "log_info('【步骤5】基线模型将在整体交叉验证中一并运行。')\n",
        "log_info('【步骤5摘要】基线模型性能将作为后续对比基准。')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d878a657",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y 全局标签分布： (array([0, 1]), array([43751,  5144], dtype=int64))\n",
            "原始标签列分布：\n",
            "price\n",
            "100    2051\n",
            "150    2047\n",
            "50     1534\n",
            "60     1458\n",
            "200    1401\n",
            "       ... \n",
            "780       1\n",
            "386       1\n",
            "888       1\n",
            "483       1\n",
            "338       1\n",
            "Name: count, Length: 674, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print(\"y 全局标签分布：\", np.unique(y, return_counts=True))\n",
        "\n",
        "print(\"原始标签列分布：\")\n",
        "print(df_raw[cfg['DATA']['target_col']].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ea26cda5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "【INFO】【2025-12-11 17:31:56】【基线-RF】使用决策阈值=0.400（fixed 模式）\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 步骤6：运行 BTTWD k 折实验（含基线）\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m run_kfold_experiments(X, y, df_raw\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATA\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_col\u001b[39m\u001b[38;5;124m'\u001b[39m]]), cfg)\n\u001b[0;32m      3\u001b[0m summary_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root_path, cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOUTPUT\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults_dir\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics_kfold_summary.csv\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      4\u001b[0m display(summary_df)\n",
            "File \u001b[1;32me:\\yan\\组\\三支决策\\机器学习\\BT_TWD\\bttwdlib\\cv_runner.py:216\u001b[0m, in \u001b[0;36mrun_kfold_experiments\u001b[1;34m(X, y, X_df_for_bucket, cfg, test_data, bucket_tree)\u001b[0m\n\u001b[0;32m    214\u001b[0m     baseline_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogReg\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m train_eval_logreg(X, y, cfg, skf, costs\u001b[38;5;241m=\u001b[39mthreshold_costs)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_forest\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m baseline_set:\n\u001b[1;32m--> 216\u001b[0m     baseline_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomForest\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m train_eval_random_forest(X, y, cfg, skf, costs\u001b[38;5;241m=\u001b[39mthreshold_costs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mknn\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m baseline_set:\n\u001b[0;32m    218\u001b[0m     baseline_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKNN\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m train_eval_knn(X, y, cfg, skf, costs\u001b[38;5;241m=\u001b[39mthreshold_costs)\n",
            "File \u001b[1;32me:\\yan\\组\\三支决策\\机器学习\\BT_TWD\\bttwdlib\\baselines.py:192\u001b[0m, in \u001b[0;36mtrain_eval_random_forest\u001b[1;34m(X, y, cfg, cv_splitter, costs)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_builder\u001b[39m():\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m RandomForestClassifier(\n\u001b[0;32m    186\u001b[0m         n_estimators\u001b[38;5;241m=\u001b[39mrf_cfg\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m200\u001b[39m),\n\u001b[0;32m    187\u001b[0m         max_depth\u001b[38;5;241m=\u001b[39mrf_cfg\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    188\u001b[0m         random_state\u001b[38;5;241m=\u001b[39mrf_cfg\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m42\u001b[39m),\n\u001b[0;32m    189\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEXP\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    190\u001b[0m     )\n\u001b[1;32m--> 192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _run_baseline_cv(_builder, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRF\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_forest\u001b[39m\u001b[38;5;124m\"\u001b[39m, X, y, cfg, cv_splitter, costs\u001b[38;5;241m=\u001b[39mcosts)\n",
            "File \u001b[1;32me:\\yan\\组\\三支决策\\机器学习\\BT_TWD\\bttwdlib\\baselines.py:151\u001b[0m, in \u001b[0;36m_run_baseline_cv\u001b[1;34m(model_builder, model_name, model_key, X, y, cfg, cv_splitter, costs)\u001b[0m\n\u001b[0;32m    149\u001b[0m     fold_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X[train_idx], y[train_idx])\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(clf, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    154\u001b[0m     y_score \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict_proba(X[test_idx])[:, \u001b[38;5;241m1\u001b[39m]\n",
            "File \u001b[1;32md:\\Anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32md:\\Anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 348\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    349\u001b[0m     X, y, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mDTYPE\n\u001b[0;32m    350\u001b[0m )\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
            "File \u001b[1;32md:\\Anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
            "File \u001b[1;32md:\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
            "File \u001b[1;32md:\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[0;32m    960\u001b[0m             array,\n\u001b[0;32m    961\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    962\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    963\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
            "File \u001b[1;32md:\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    125\u001b[0m     X,\n\u001b[0;32m    126\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[0;32m    127\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[0;32m    129\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m    130\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m    131\u001b[0m )\n",
            "File \u001b[1;32md:\\Anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
            "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
          ]
        }
      ],
      "source": [
        "# 步骤6：运行 BTTWD k 折实验（含基线）\n",
        "results = run_kfold_experiments(X, y, df_raw.drop(columns=[cfg['DATA']['target_col']]), cfg)\n",
        "summary_df = pd.read_csv(os.path.join(root_path, cfg['OUTPUT']['results_dir'], 'metrics_kfold_summary.csv'))\n",
        "display(summary_df)\n",
        "summary_df.plot(x='model', kind='bar', figsize=(8,4), title='模型指标对比')\n",
        "fig_compare = os.path.join(root_path, cfg['OUTPUT']['figs_dir'], 'metrics_compare.png')\n",
        "plt.savefig(fig_compare, bbox_inches='tight')\n",
        "plt.close()\n",
        "log_info('【步骤6摘要】BTTWD 与基线的 k 折结果已生成并保存。')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd807b8c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 步骤7：桶级别分析\n",
        "bucket_metrics_path = os.path.join(root_path, cfg['OUTPUT']['results_dir'], 'bucket_metrics.csv')\n",
        "if os.path.exists(bucket_metrics_path):\n",
        "    bucket_metrics_df = pd.read_csv(bucket_metrics_path)\n",
        "    display(bucket_metrics_df.head())\n",
        "    bucket_metrics_df.plot(x='bucket_id', y='pos_rate_all', kind='bar', figsize=(12,4), title='桶正类比例')\n",
        "    plt.ylabel('正类比例')\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(fig_bucket, bbox_inches='tight')\n",
        "    plt.close()\n",
        "log_info('【步骤7摘要】桶级指标已整理，可用于局部化分析。')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9bc0d7d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 步骤8：结果汇总\n",
        "log_info('【步骤8】检查结果文件与图表。')\n",
        "print(os.listdir(os.path.join(root_path, cfg['OUTPUT']['results_dir'])))\n",
        "print(os.listdir(os.path.join(root_path, cfg['OUTPUT']['figs_dir'])))\n",
        "log_info('【全部步骤完成】Airbnb NYC 数据集上的 BT-TWD 实验结束。')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
