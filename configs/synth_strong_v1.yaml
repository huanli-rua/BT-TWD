DATA:
  dataset_name: "synth_strong_v1"
  raw_path: "../data/synth/synth_strong_v1.csv"
  target_col: "target"
  positive_label: 1
  negative_label: 0
  file_type: "csv"
  use_kfold: true
  kfold:
    n_splits: 5
    shuffle: true
    random_state: 42
  split:
    strategy: "random_stratified"
    train_ratio: 0.6
    val_ratio: 0.2
    test_ratio: 0.2
    random_state: 42

PREPROCESS:
  continuous_cols:
    - x1
    - x2
    - x3
    - x4
    - x5
    - x6
    - x7
    - x8
    - x9
    - x10
    - z1
    - z2
    - z3
    - z4
    - z5
  categorical_cols:
    - group
  handle_missing: "none"
  scaler_type: "standard"
  drop_first: true
  save_feature_names: true

SCORE:
  bucket_score_mode: "f1_regret_bnd"
  f1_weight: 1.0
  regret_weight: 1.0
  bnd_weight: 0.5

BTTWD:
  bucket_levels:
    - level: 1
      name: "L1_group"
      type: "categorical_group"
      col: "group"
      groups:
        - label: "A"
          values: ["A"]
        - label: "B"
          values: ["B"]
        - label: "C"
          values: ["C"]
        - label: "D"
          values: ["D"]
      other_label: "OTHER"
    - level: 2
      name: "L2_x1"
      type: "numeric_bin"
      col: "x1"
      bins: [-0.5, 0.5]
      labels: ["low", "mid", "high"]
  min_bucket_size: 200
  use_min_bucket_size_limit: true
  use_merge_small_to_residual: true # 是否将小于 min_bucket_size 的子桶合并到 residual/others（与最小样本限制解耦）
  max_levels: 2
  use_gain: false
  min_gain_for_split: 0.0
  use_gain_weak_backoff: true
  gamma_bucket: 0.0
  bucket_subsample: 0.7
  max_train_samples_per_bucket: 30000
  use_parent_share_rate: true
  parent_share_rate: 0.2
  min_parent_share: 50
  val_ratio: 0.3
  min_val_samples_per_bucket: 100
  use_global_backoff: true
  global_estimator: "xgb"
  bucket_estimator: "none"
  posterior_estimator: "logreg"
  logreg_C: 1.0
  knn_k: 6
  bucket_rf:
    n_estimators: 100
    max_depth: null
    random_state: 42
    n_jobs: -1
  bucket_xgb:
    n_estimators: 200
    max_depth: 3
    learning_rate: 0.1
    subsample: 0.8
    colsample_bytree: 0.8
    reg_lambda: 1.0
    random_state: 42
    n_jobs: -1
  global_xgb:
    n_estimators: 200
    max_depth: 4
    learning_rate: 0.1
    subsample: 0.8
    colsample_bytree: 0.8
    reg_lambda: 1.0
    random_state: 42
    n_jobs: -1

THRESHOLD:
  mode: "bucket_wise"
  objective: "regret"
  alpha_grid: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
  beta_grid:  [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
  gap_min: 0.1
  costs:
    C_TP: 0.0
    C_TN: 0.0
    C_FP: 1.0
    C_FN: 3.0
    C_BP: 1.0
    C_BN: 0.5
  min_samples_for_thresholds: 100

BASELINES:
  use_logreg: true
  use_random_forest: true
  use_knn: true
  use_xgboost: true
  common:
    threshold_mode: "fixed"           # 基线也按 α/β 网格搜索，保持与 BT 阈值策略可比
    fixed_threshold: 0.3
  logreg:
    C: 1.0
    max_iter: 300
    use_custom_threshold: false
    custom_threshold: 0.35
  random_forest:
    n_estimators: 200
    max_depth: null
    random_state: 42
    use_custom_threshold: false
    custom_threshold: 0.4
  xgboost:
    n_estimators: 300
    max_depth: 4
    learning_rate: 0.1
    subsample: 0.8
    colsample_bytree: 0.8
    reg_lambda: 1.0
    random_state: 42
    n_jobs: -1
    use_custom_threshold: false
    custom_threshold: 0.35

tSNE:
  sample_size: 2000      # 可视化使用的最大样本数，<=0 表示不截断
  perplexity: 30.0       # t-SNE 的 perplexity 参数
  learning_rate: 200.0   # t-SNE 的学习率
  random_state: 42       # 随机种子，控制采样和 t-SNE 复现性

OUTPUT:
  results_dir: "results/synth_strong_v1"
  figs_dir: "figs"

  # ✅ 对齐 adult：折级输出（你后面统计强桶优势比例要用）
  save_per_fold_metrics: true
  save_bucket_metrics: true
  save_config_copy: true
  save_threshold_logs: true
  threshold_log_filename: "bucket_thresholds_per_fold.csv"

SEED:
  global_seed: 42
