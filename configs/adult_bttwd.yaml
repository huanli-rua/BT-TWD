DATA:
  dataset_name: "adult"
  raw_path: "../data/adult/adult.data"
  target_col: "income"
  positive_label: ">50K"
  use_kfold: true
  n_splits: 5
  shuffle: true
  stratify: true
  random_state: 42

PREPROCESS:
  continuous_cols:
    - "age"
    - "fnlwgt"
    - "education-num"
    - "capital-gain"
    - "capital-loss"
    - "hours-per-week"
  categorical_cols:
    - "workclass"
    - "education"
    - "marital-status"
    - "occupation"
    - "relationship"
    - "race"
    - "sex"
    - "native-country"
  handle_missing: "question_mark"
  fillna_strategy: "most_frequent"
  scale_continuous: true
  scaler_type: "standard"
  encoding_type: "onehot"
  drop_first: true
  save_feature_names: true

BTTWD:
  bucket_levels:
    - level: 1
      name: "L1_age"
      type: "numeric_bin"
      col: "age"
      bins: [25, 35, 50]             # (-inf,25], (25,35], (35,50], (50,inf)
      labels: ["young", "mid", "old", "very_old"]

    - level: 2
      name: "L2_education"
      type: "categorical_group"
      col: "education"
      groups:
        low:  ["Preschool", "1st-4th", "5th-6th", "7th-8th"]
        mid:  ["9th", "10th", "11th", "12th", "HS-grad"]
        high: ["Assoc-acdm", "Assoc-voc", "Some-college", "Bachelors"]
        top:  ["Masters", "Doctorate", "Prof-school"]
      default_group: "unknown"       # 没在上面这些里的，统一归到 unknown

    - level: 3
      name: "L3_hours"
      type: "numeric_bin"
      col: "hours-per-week"
      # 示例分法：<35 = 低工时，35-45 = 标准工作，>45 = 加班型
      bins: [35, 45]
      labels: ["low_hours", "normal_hours", "high_hours"]
  min_bucket_size: 50              # 叶子桶若不足该数量就不单独建模，直接并入父桶
  parent_share_rate: 0.2           # 大桶向父桶贡献的样本比例
  min_parent_share: 50             # 大桶向父桶贡献样本的最少数量
  max_depth: 3                    # 支持到 3 层 BT
  val_ratio: 0.2                   # 训练集中按该比例划分验证集用来选阈值
  min_val_samples_per_bucket: 20   # 每个桶用于阈值搜索的最少验证集样本数
  use_global_backoff: true         # 若桶和父桶都没有模型时是否回退使用全局模型
  global_estimator: "xgb"          # 全局兜底模型类型
  bucket_estimator: "knn"          # 桶内局部模型类型
  posterior_estimator: "logreg"    # 后验概率校准或二分类模型类型
  logreg_C: 1.0                    # 逻辑回归的正则化强度
  knn_k: 10                        # KNN 模型的邻居数
  global_xgb:                      # 全局 XGBoost 模型参数
    n_estimators: 300              # 迭代树数
    max_depth: 4                   # 树最大深度
    learning_rate: 0.1             # 学习率
    subsample: 0.8                 # 行采样比例
    colsample_bytree: 0.8          # 列采样比例
    reg_lambda: 1.0                # L2 正则项
    random_state: 42               # 随机种子
    n_jobs: -1                     # 并行线程数

THRESHOLDS:
  mode: "bucket_wise"
  objective: "regret"
  alpha_grid: [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]
  beta_grid:  [0.0, 0.1, 0.2, 0.3, 0.4]
  gap_min: 0.05
  costs:
    C_TP: 0.0
    C_TN: 0.0
    C_FP: 1.0
    C_FN: 3.0
    C_BP: 1.5
    C_BN: 0.5
  min_samples_for_thresholds: 100


BASELINES:
  use_logreg: true
  use_random_forest: true
  use_knn: true
  use_xgboost: true
  logreg:
    C: 1.0
    max_iter: 500
  random_forest:
    n_estimators: 200
    max_depth: null
    random_state: 42

  knn:
    n_neighbors: 6

  xgboost:
    n_estimators: 300
    max_depth: 4
    learning_rate: 0.1
    subsample: 0.8
    colsample_bytree: 0.8
    reg_lambda: 1.0
    random_state: 42
    n_jobs: -1

EXP:
  kfold_repeats: 1
  n_jobs: -1
  verbose: 1

METRICS:
  use_metrics: ["Precision", "Recall", "F1", "BAC", "AUC", "MCC", "Kappa", "Regret"]
  pos_label: 1

OUTPUT:
  results_dir: "results"
  figs_dir: "figs"
  save_per_fold_metrics: true
  save_bucket_metrics: true
  save_config_copy: true
  save_threshold_logs: true
  threshold_log_filename: "bucket_thresholds_per_fold.csv"

SEED:
  global_seed: 42
